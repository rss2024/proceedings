<html> 
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />  
<head>  
<meta name="citation_title" content="Combined Optimization and Reinforcement Learning for Manipulation Skills" />  
<meta name="citation_author" content="Peter Englert" />  
<meta name="citation_author" content="Marc Toussaint" />  
<meta name="citation_publication_date" content="2016/06/18" />  
<meta name="citation_conference_title" content="Robotics: Science and Systems XII" />  
<meta name="citation_isbn" content="9780262701143" />  
<meta name="citation_volume" content="12" />  
<meta name="citation_pdf_url" content="p33.pdf" />  
<title>Robotics: Science and Systems XII - Online Proceedings</title>  
<link type="text/css" rel="stylesheet" href="../style.css">  
<!--[if IE 5]> 
<link type="text/css" rel="stylesheet" href="../ie5.css"> 
<![endif]-->  
<!--[if IE 6]> 
<link type="text/css" rel="stylesheet" href="../ie6.css"> 
<![endif]-->  
</head>  
<body>  
<div class="menu">  
<ul>
<li class="here"><a class="menu" href="../index.html">Home</a></li>
<li class="label">RSS XIX</span></li>
<li class="menu"><a class="menu" href="../rss19/index.html">Content</a></li>
<li class="menu"><a class="menu" href="../rss19/authors.html">Authors</a></li>
<li class="label">RSS XVIII</span></li>
<li class="menu"><a class="menu" href="../rss18/index.html">Content</a></li>
<li class="menu"><a class="menu" href="../rss18/authors.html">Authors</a></li>
<li class="label">RSS XVII</span></li>
<li class="menu"><a class="menu" href="../rss17/index.html">Content</a></li>
<li class="menu"><a class="menu" href="../rss17/authors.html">Authors</a></li>
<li class="label">RSS XVI</span></li>
<li class="menu"><a class="menu" href="../rss16/index.html">Content</a></li>
<li class="menu"><a class="menu" href="../rss16/authors.html">Authors</a></li>
<li class="label">RSS XV</span></li>
<li class="menu"><a class="menu" href="../rss15/index.html">Content</a></li>
<li class="menu"><a class="menu" href="../rss15/authors.html">Authors</a></li>
<li class="label">RSS XIV</span></li>
<li class="menu"><a class="menu" href="../rss14/index.html">Content</a></li>
<li class="menu"><a class="menu" href="../rss14/authors.html">Authors</a></li>
<li class="label">RSS XIII</span></li>
<li class="menu"><a class="menu" href="../rss13/index.html">Content</a></li>
<li class="menu"><a class="menu" href="../rss13/authors.html">Authors</a></li>
<li class="label">RSS XII</span></li>
<li class="menu"><a class="menu" href="../rss12/index.html">Content</a></li>
<li class="menu"><a class="menu" href="../rss12/authors.html">Authors</a></li>
<li class="label">RSS XI</span></li>
<li class="menu"><a class="menu" href="../rss11/index.html">Content</a></li>
<li class="menu"><a class="menu" href="../rss11/authors.html">Authors</a></li>
<li class="label">RSS X</span></li>
<li class="menu"><a class="menu" href="../rss10/index.html">Content</a></li>
<li class="menu"><a class="menu" href="../rss10/authors.html">Authors</a></li>
<li class="label">RSS IX</span></li>
<li class="menu"><a class="menu" href="../rss09/index.html">Content</a></li>
<li class="menu"><a class="menu" href="../rss09/authors.html">Authors</a></li>
<li class="label">RSS VIII</span></li>
<li class="menu"><a class="menu" href="../rss08/index.html">Content</a></li>
<li class="menu"><a class="menu" href="../rss08/authors.html">Authors</a></li>
<li class="label">RSS VII</span></li>
<li class="menu"><a class="menu" href="../rss07/index.html">Content</a></li>
<li class="menu"><a class="menu" href="../rss07/authors.html">Authors</a></li>
<li class="label">RSS VI</span></li>
<li class="menu"><a class="menu" href="../rss06/index.html">Content</a></li>
<li class="menu"><a class="menu" href="../rss06/authors.html">Authors</a></li>
<li class="label">RSS V</span></li>
<li class="menu"><a class="menu" href="../rss05/index.html">Content</a></li>
<li class="menu"><a class="menu" href="../rss05/authors.html">Authors</a></li>
<li class="label">RSS IV</span></li>
<li class="menu"><a class="menu" href="../rss04/index.html">Content</a></li>
<li class="menu"><a class="menu" href="../rss04/authors.html">Authors</a></li>
<li class="label">RSS III</span></li>
<li class="menu"><a class="menu" href="../rss03/index.html">Content</a></li>
<li class="menu"><a class="menu" href="../rss03/authors.html">Authors</a></li>
<li class="label">RSS II</span></li>
<li class="menu"><a class="menu" href="../rss02/index.html">Content</a></li>
<li class="menu"><a class="menu" href="../rss02/authors.html">Authors</a></li>
<li class="label">RSS I</span></li>
<li class="menu"><a class="menu" href="../rss01/index.html">Content</a></li>
<li class="menu"><a class="menu" href="../rss01/authors.html">Authors</a></li>
<li class="label">Ethics and Malpractice</span></li>
<li class="menu"><a class="menu" href="../statement.html">Statement</a></li>
<li class="label">Contact</span></li>
<li class="last"><a class="menu" href="../contact.html">Webmaster</a></li>
<li class="no-style"><center><img border="0" src="../robot-small.jpg"></center>
<br><br><br>
<center>We are using google analytics for statistics!</center>
</ul>
</div>  
<div class="content">  
  
<h1>Robotics: Science and Systems XII</h1>  
<h3>Combined Optimization and Reinforcement Learning for Manipulation Skills</h3> 
<i>Peter Englert, Marc Toussaint</i><br>  
<p>  
<b>Abstract:</b>  
</p><p style="text-align: justify;">  
This work addresses the problem of how a robot can improve a manipulation skill in a sample-efficient and secure manner. As an alternative to the standard reinforcement learning formulation where all objectives are defined in a single reward function, we propose a generalized formulation that consists of three components: 1) A known analytic control cost function; 2) A black-box return function; and 3) A black-box binary success constraint. While the overall policy optimization problem is high- dimensional, in typical robot manipulation problems we can assume that the black-box return and constraint only depend on a lower-dimensional projection of the solution. With our formulation we can exploit this structure for a sample-efficient learning framework that iteratively improves the policy with respect to the objective functions under the success constraint. We employ efficient 2nd-order optimization methods to optimize the high-dimensional policy w.r.t. the analytic cost function while keeping the lower dimensional projection fixed. This is alternated with safe Bayesian optimization over the lower-dimensional projection to address the black-box return and success constraint. During both improvement steps the success constraint is used to keep the optimization in a secure region and to clearly distinguish between motions that lead to success or failure. The learning algorithm is evaluated on a simulated benchmark problem and a door opening task with a PR2. 
</p>  
<p>  
<b>Download:</b> <a href="p33.pdf" target="_blank" onclick="_gaq.push(['_trackEvent','rss12/p33.pdf','PDF',this.href]);"><img src="../icon-pdf.png" border=0></a> 
</p>  
<p>  
<b>Bibtex:</b>  
<pre>  
@INPROCEEDINGS{Englert-RSS-16, 
    AUTHOR    = {Peter Englert AND Marc Toussaint}, 
    TITLE     = {Combined Optimization and Reinforcement Learning for Manipulation Skills}, 
    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, 
    YEAR      = {2016}, 
    ADDRESS   = {AnnArbor, Michigan}, 
    MONTH     = {June}, 
    DOI       = {10.15607/RSS.2016.XII.033} 
} 
  
</pre>  
</p>  
  
</div>  
<div class="analyt"> 
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-24631810-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</div> 
</body>  
</html> 
